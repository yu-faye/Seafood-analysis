# ğŸ”— é›†æˆç°æœ‰Azure Data FactoryæŒ‡å—

å¦‚æœæ‚¨å·²ç»æœ‰ä¸€ä¸ªç°æœ‰çš„Azure Data Factoryå¹¶åŒæ­¥åœ¨GitHubä¸Šï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é›†æˆæ–°çš„Global Fishing Watchåˆ†æåŠŸèƒ½ã€‚

## ğŸ“ æ–‡ä»¶å¤åˆ¶æ¸…å•

### 1. æ ¸å¿ƒé…ç½®æ–‡ä»¶
å¤åˆ¶è¿™äº›æ–‡ä»¶åˆ°æ‚¨ç°æœ‰çš„ADFä»“åº“ï¼š

```
ç°æœ‰ADFä»“åº“/
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ fishing-events-pipeline.json          # æ–°å¢ï¼šæ¸”ä¸šäº‹ä»¶å¤„ç†ç®¡é“
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ gfw-events-api.json                   # æ–°å¢ï¼šGFW APIæ•°æ®é›†
â”‚   â”œâ”€â”€ raw-fishing-events-data.json          # æ–°å¢ï¼šåŸå§‹æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ processed-fishing-events-data.json    # æ–°å¢ï¼šå¤„ç†åæ•°æ®
â”‚   â””â”€â”€ fishing-events-table.json             # æ–°å¢ï¼šæ•°æ®åº“è¡¨æ˜ å°„
â”œâ”€â”€ linkedServices/
â”‚   â”œâ”€â”€ global-fishing-watch-api.json         # æ–°å¢ï¼šGFW APIè¿æ¥
â”‚   â””â”€â”€ azure-databricks-linked-service.json  # æ–°å¢ï¼šDatabricksè¿æ¥
â””â”€â”€ scripts/
    â””â”€â”€ databricks-fishing-events-processor.py # æ–°å¢ï¼šæ•°æ®å¤„ç†è„šæœ¬
```

### 2. æ•°æ®åº“è„šæœ¬
```
sql/
â””â”€â”€ create-fishing-events-tables.sql          # æ–°å¢ï¼šæ•°æ®åº“è¡¨ç»“æ„
```

### 3. éƒ¨ç½²è„šæœ¬ï¼ˆå¯é€‰ï¼‰
```
deployment/
â”œâ”€â”€ deploy-to-existing-adf.ps1                # ä¸“é—¨ç”¨äºç°æœ‰ADF
â”œâ”€â”€ simple-deploy.sh                          # ç®€åŒ–éƒ¨ç½²è„šæœ¬
â””â”€â”€ step-by-step-deploy.sh                    # åˆ†æ­¥éª¤éƒ¨ç½²
```

## ğŸ”§ é›†æˆæ­¥éª¤

### æ­¥éª¤1ï¼šå¤åˆ¶æ–‡ä»¶åˆ°ç°æœ‰ä»“åº“
```bash
# åœ¨æ‚¨çš„ç°æœ‰ADFä»“åº“ç›®å½•ä¸­
cp -r /path/to/azure-adf-setup/pipelines/* ./pipeline/
cp -r /path/to/azure-adf-setup/datasets/* ./dataset/
cp -r /path/to/azure-adf-setup/linked-services/* ./linkedService/
```

### æ­¥éª¤2ï¼šæ›´æ–°ç°æœ‰é“¾æ¥æœåŠ¡
å¦‚æœæ‚¨å·²ç»æœ‰Azure Storageå’ŒSQL Databaseçš„é“¾æ¥æœåŠ¡ï¼Œéœ€è¦ï¼š

1. **æ›´æ–°å­˜å‚¨é“¾æ¥æœåŠ¡**ï¼šç¡®ä¿æ”¯æŒData Lake Gen2
2. **æ·»åŠ GFW APIé“¾æ¥æœåŠ¡**ï¼šæ–°å¢Global Fishing Watch APIè¿æ¥
3. **æ·»åŠ Databricksé“¾æ¥æœåŠ¡**ï¼šå¦‚æœä½¿ç”¨Databrickså¤„ç†

### æ­¥éª¤3ï¼šéƒ¨ç½²åˆ°ç°æœ‰ADF
ä½¿ç”¨ä¸“é—¨çš„è„šæœ¬ï¼š
```powershell
# ä½¿ç”¨ç°æœ‰ADFçš„éƒ¨ç½²è„šæœ¬
.\deployment\deploy-to-existing-adf.ps1 `
    -ResourceGroupName "your-existing-rg" `
    -DataFactoryName "your-existing-adf" `
    -GFWApiToken "your-token"
```

### æ­¥éª¤4ï¼šåˆ›å»ºæ•°æ®åº“è¡¨
åœ¨æ‚¨ç°æœ‰çš„SQLæ•°æ®åº“ä¸­æ‰§è¡Œï¼š
```sql
-- è¿è¡Œ sql/create-fishing-events-tables.sql
-- è¿™ä¼šåˆ›å»ºæ¸”ä¸šåˆ†ææ‰€éœ€çš„è¡¨ç»“æ„
```

## ğŸ“‹ æ–‡ä»¶æ˜ å°„å¯¹ç…§è¡¨

| azure-adf-setup æ–‡ä»¶ | ç°æœ‰ADFä»“åº“ä½ç½® | è¯´æ˜ |
|---------------------|----------------|------|
| `pipelines/fishing-events-pipeline.json` | `pipeline/` | ä¸»è¦åˆ†æç®¡é“ |
| `datasets/gfw-events-api.json` | `dataset/` | APIæ•°æ®é›† |
| `datasets/raw-fishing-events-data.json` | `dataset/` | åŸå§‹æ•°æ® |
| `datasets/processed-fishing-events-data.json` | `dataset/` | å¤„ç†æ•°æ® |
| `datasets/fishing-events-table.json` | `dataset/` | æ•°æ®åº“è¡¨ |
| `linkedServices/global-fishing-watch-api.json` | `linkedService/` | APIè¿æ¥ |
| `linkedServices/azure-databricks-linked-service.json` | `linkedService/` | Databricksè¿æ¥ |

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å‘½åå†²çª
- æ£€æŸ¥æ˜¯å¦æœ‰åŒåçš„pipelineã€datasetæˆ–linkedService
- å¦‚æœ‰å†²çªï¼Œé‡å‘½åæ–°æ–‡ä»¶æˆ–åˆå¹¶åŠŸèƒ½

### 2. å‚æ•°é…ç½®
- æ›´æ–°pipelineä¸­çš„å‚æ•°ä»¥åŒ¹é…æ‚¨çš„ç¯å¢ƒ
- ç¡®ä¿å­˜å‚¨è´¦æˆ·åã€æ•°æ®åº“åç­‰é…ç½®æ­£ç¡®

### 3. æƒé™è®¾ç½®
- ç¡®ä¿ADFæœ‰è®¿é—®GFW APIçš„æƒé™
- éªŒè¯Databricksé›†ç¾¤çš„è®¿é—®æƒé™

## ğŸš€ å¿«é€Ÿé›†æˆå‘½ä»¤

å¦‚æœæ‚¨çš„ç°æœ‰ADFä»“åº“ç»“æ„æ ‡å‡†ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªå¿«é€Ÿè„šæœ¬ï¼š

```bash
#!/bin/bash
# å¿«é€Ÿé›†æˆè„šæœ¬

EXISTING_ADF_REPO="/path/to/your/existing/adf/repo"
SOURCE_DIR="/path/to/azure-adf-setup"

# å¤åˆ¶ç®¡é“
cp "$SOURCE_DIR/pipelines/fishing-events-pipeline.json" "$EXISTING_ADF_REPO/pipeline/"

# å¤åˆ¶æ•°æ®é›†
cp "$SOURCE_DIR/datasets/"*.json "$EXISTING_ADF_REPO/dataset/"

# å¤åˆ¶é“¾æ¥æœåŠ¡
cp "$SOURCE_DIR/linked-services/"*.json "$EXISTING_ADF_REPO/linkedService/"

# å¤åˆ¶è„šæœ¬
mkdir -p "$EXISTING_ADF_REPO/scripts"
cp "$SOURCE_DIR/scripts/databricks-fishing-events-processor.py" "$EXISTING_ADF_REPO/scripts/"

# å¤åˆ¶SQLè„šæœ¬
mkdir -p "$EXISTING_ADF_REPO/sql"
cp "$SOURCE_DIR/sql/create-fishing-events-tables.sql" "$EXISTING_ADF_REPO/sql/"

echo "âœ… æ–‡ä»¶é›†æˆå®Œæˆï¼"
echo "ğŸ“‹ ä¸‹ä¸€æ­¥ï¼š"
echo "  1. æ£€æŸ¥æ–‡ä»¶å‘½åå†²çª"
echo "  2. æ›´æ–°é…ç½®å‚æ•°"
echo "  3. éƒ¨ç½²åˆ°ADF"
echo "  4. åˆ›å»ºæ•°æ®åº“è¡¨"
```

## ğŸ”„ GitHubåŒæ­¥

é›†æˆå®Œæˆåï¼š
```bash
cd /path/to/your/existing/adf/repo
git add .
git commit -m "feat: Add Global Fishing Watch analysis pipeline

- Add fishing events processing pipeline
- Add GFW API datasets and linked services  
- Add Databricks processing script
- Add SQL schema for port visit analysis"
git push origin main
```

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœåœ¨é›†æˆè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š
1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œå‘½åçº¦å®š
2. éªŒè¯JSONæ ¼å¼æ˜¯å¦æ­£ç¡®
3. ç¡®è®¤æ‰€æœ‰ä¾èµ–çš„é“¾æ¥æœåŠ¡éƒ½å·²åˆ›å»º
4. æµ‹è¯•ç®¡é“çš„è¿æ¥å’Œæƒé™

é›†æˆå®Œæˆåï¼Œæ‚¨å°±å¯ä»¥åœ¨ç°æœ‰çš„ADFä¸­ä½¿ç”¨Global Fishing Watchåˆ†æåŠŸèƒ½äº†ï¼
